//Import Required Classes
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
//Create a Sample Dataset
val data = Seq(
  (1, "Alice", 85),
  (2, "Bob", 92),
  (3, "Charlie", 70),
  (4, "David", 65),
  (5, "Eve", 99)
)

val df = spark.createDataFrame(data).toDF("id", "name", "score")
//Check the data:
df.show()

//Use withColumn()
val df2 = df.withColumn(
  "grade",
  when(col("score") >= 90, "A")
    .when(col("score") >= 75, "B")
    .otherwise("C")
)
//Show the Updated DataFrame
df2.show()

//Use withColumnRenamed()
val df3 = df2.withColumnRenamed("score", "marks")

//Show the Result
df3.show()

//Now you’ve seen:
withColumn() → add or transform a column
withColumnRenamed() → rename a column

//Use drop()
val df4 = df3.drop("marks")

//Show the Result
df4.show()

//Now you’ve seen:

withColumn() → add/transform column
withColumnRenamed() → rename column
drop() → remove column
